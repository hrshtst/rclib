{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"rclib: Reservoir Computing Library","text":"<p>rclib is a high-performance, scalable, and general-purpose reservoir computing framework implemented in C++ with Python bindings. It is designed to handle both small-scale networks and medium-to-large scale architectures, supporting deep (stacked) and parallel reservoir configurations.</p>"},{"location":"#project-goals","title":"Project Goals","text":"<ul> <li>Performance: Core logic in C++17 using Eigen for linear algebra.</li> <li>Scalability: Efficient handling of sparse reservoirs and complex architectures.</li> <li>Flexibility: Modular design separating Reservoirs and Readouts.</li> <li>Ease of Use: Pythonic interface via <code>pybind11</code> and <code>scikit-learn</code> style API.</li> <li>Reproducibility: Deterministic results via explicit seeding of random reservoirs.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To get started with <code>rclib</code>, please refer to the User Guide for installation and basic usage instructions.</p> <p>For a deep dive into the underlying mathematics and architecture, check the Theory section.</p> <p>Detailed class and function documentation can be found in the API Reference.</p>"},{"location":"api/","title":"API Reference","text":"<p>This section documents the Python API for <code>rclib</code>. The C++ core is wrapped efficiently to provide a seamless experience.</p>"},{"location":"api/#reservoirs","title":"Reservoirs","text":""},{"location":"api/#rclib.reservoirs","title":"<code>rclib.reservoirs</code>","text":"<p>Reservoir configurations.</p>"},{"location":"api/#rclib.reservoirs.RandomSparse","title":"<code>RandomSparse</code>","text":"<p>Random Sparse Reservoir configuration.</p> Source code in <code>python/rclib/reservoirs.py</code> <pre><code>class RandomSparse:\n    \"\"\"Random Sparse Reservoir configuration.\"\"\"\n\n    def __init__(\n        self,\n        n_neurons: int,\n        spectral_radius: float,\n        sparsity: float = 0.1,\n        leak_rate: float = 1.0,\n        input_scaling: float = 1.0,\n        *,\n        include_bias: bool = False,\n        seed: int = 42,\n    ) -&gt; None:\n        \"\"\"Initialize the Random Sparse Reservoir.\n\n        Args:\n            n_neurons: Number of neurons in the reservoir.\n            spectral_radius: Spectral radius of the reservoir weight matrix.\n            sparsity: Sparsity of the reservoir weight matrix (0.0 to 1.0).\n            leak_rate: Leaking rate of the neurons.\n            input_scaling: Scaling factor for the input weights.\n            include_bias: Whether to include a bias term.\n            seed: Random seed for weights initialization.\n        \"\"\"\n        self.n_neurons = n_neurons\n        self.spectral_radius = spectral_radius\n        self.sparsity = sparsity\n        self.leak_rate = leak_rate\n        self.input_scaling = input_scaling\n        self.include_bias = include_bias\n        self.seed = seed\n</code></pre>"},{"location":"api/#rclib.reservoirs.RandomSparse.__init__","title":"<code>__init__(n_neurons, spectral_radius, sparsity=0.1, leak_rate=1.0, input_scaling=1.0, *, include_bias=False, seed=42)</code>","text":"<p>Initialize the Random Sparse Reservoir.</p> <p>Args:     n_neurons: Number of neurons in the reservoir.     spectral_radius: Spectral radius of the reservoir weight matrix.     sparsity: Sparsity of the reservoir weight matrix (0.0 to 1.0).     leak_rate: Leaking rate of the neurons.     input_scaling: Scaling factor for the input weights.     include_bias: Whether to include a bias term.     seed: Random seed for weights initialization.</p> Source code in <code>python/rclib/reservoirs.py</code> <pre><code>def __init__(\n    self,\n    n_neurons: int,\n    spectral_radius: float,\n    sparsity: float = 0.1,\n    leak_rate: float = 1.0,\n    input_scaling: float = 1.0,\n    *,\n    include_bias: bool = False,\n    seed: int = 42,\n) -&gt; None:\n    \"\"\"Initialize the Random Sparse Reservoir.\n\n    Args:\n        n_neurons: Number of neurons in the reservoir.\n        spectral_radius: Spectral radius of the reservoir weight matrix.\n        sparsity: Sparsity of the reservoir weight matrix (0.0 to 1.0).\n        leak_rate: Leaking rate of the neurons.\n        input_scaling: Scaling factor for the input weights.\n        include_bias: Whether to include a bias term.\n        seed: Random seed for weights initialization.\n    \"\"\"\n    self.n_neurons = n_neurons\n    self.spectral_radius = spectral_radius\n    self.sparsity = sparsity\n    self.leak_rate = leak_rate\n    self.input_scaling = input_scaling\n    self.include_bias = include_bias\n    self.seed = seed\n</code></pre>"},{"location":"api/#rclib.reservoirs.Nvar","title":"<code>Nvar</code>","text":"<p>NVAR Reservoir configuration.</p> Source code in <code>python/rclib/reservoirs.py</code> <pre><code>class Nvar:\n    \"\"\"NVAR Reservoir configuration.\"\"\"\n\n    def __init__(self, num_lags: int) -&gt; None:\n        \"\"\"Initialize the NVAR Reservoir.\n\n        Args:\n            num_lags: Number of time lags to include.\n        \"\"\"\n        self.num_lags = num_lags\n</code></pre>"},{"location":"api/#rclib.reservoirs.Nvar.__init__","title":"<code>__init__(num_lags)</code>","text":"<p>Initialize the NVAR Reservoir.</p> <p>Args:     num_lags: Number of time lags to include.</p> Source code in <code>python/rclib/reservoirs.py</code> <pre><code>def __init__(self, num_lags: int) -&gt; None:\n    \"\"\"Initialize the NVAR Reservoir.\n\n    Args:\n        num_lags: Number of time lags to include.\n    \"\"\"\n    self.num_lags = num_lags\n</code></pre>"},{"location":"api/#readouts","title":"Readouts","text":""},{"location":"api/#rclib.readouts","title":"<code>rclib.readouts</code>","text":"<p>Readout configurations.</p>"},{"location":"api/#rclib.readouts.Ridge","title":"<code>Ridge</code>","text":"<p>Ridge Regression Readout configuration.</p> Source code in <code>python/rclib/readouts.py</code> <pre><code>class Ridge:\n    \"\"\"Ridge Regression Readout configuration.\"\"\"\n\n    def __init__(self, alpha: float, *, include_bias: bool, solver: str = \"conjugate_gradient\") -&gt; None:\n        \"\"\"Initialize the Ridge Readout.\n\n        Args:\n            alpha: Regularization parameter.\n            include_bias: Whether to include a bias term.\n            solver: Solver to use (\"cholesky\", \"conjugate_gradient\", \"conjugate_gradient_implicit\").\n        \"\"\"\n        self.alpha = alpha\n        self.include_bias = include_bias\n        self.solver = solver\n</code></pre>"},{"location":"api/#rclib.readouts.Ridge.__init__","title":"<code>__init__(alpha, *, include_bias, solver='conjugate_gradient')</code>","text":"<p>Initialize the Ridge Readout.</p> <p>Args:     alpha: Regularization parameter.     include_bias: Whether to include a bias term.     solver: Solver to use (\"cholesky\", \"conjugate_gradient\", \"conjugate_gradient_implicit\").</p> Source code in <code>python/rclib/readouts.py</code> <pre><code>def __init__(self, alpha: float, *, include_bias: bool, solver: str = \"conjugate_gradient\") -&gt; None:\n    \"\"\"Initialize the Ridge Readout.\n\n    Args:\n        alpha: Regularization parameter.\n        include_bias: Whether to include a bias term.\n        solver: Solver to use (\"cholesky\", \"conjugate_gradient\", \"conjugate_gradient_implicit\").\n    \"\"\"\n    self.alpha = alpha\n    self.include_bias = include_bias\n    self.solver = solver\n</code></pre>"},{"location":"api/#rclib.readouts.Rls","title":"<code>Rls</code>","text":"<p>Recursive Least Squares (RLS) Readout configuration.</p> Source code in <code>python/rclib/readouts.py</code> <pre><code>class Rls:\n    \"\"\"Recursive Least Squares (RLS) Readout configuration.\"\"\"\n\n    def __init__(self, lambda_: float, delta: float, *, include_bias: bool) -&gt; None:\n        \"\"\"Initialize the RLS Readout.\n\n        Args:\n            lambda_: Forgetting factor (0.0 to 1.0).\n            delta: Initial value for the covariance matrix diagonal.\n            include_bias: Whether to include a bias term.\n        \"\"\"\n        self.lambda_ = lambda_\n        self.delta = delta\n        self.include_bias = include_bias\n</code></pre>"},{"location":"api/#rclib.readouts.Rls.__init__","title":"<code>__init__(lambda_, delta, *, include_bias)</code>","text":"<p>Initialize the RLS Readout.</p> <p>Args:     lambda_: Forgetting factor (0.0 to 1.0).     delta: Initial value for the covariance matrix diagonal.     include_bias: Whether to include a bias term.</p> Source code in <code>python/rclib/readouts.py</code> <pre><code>def __init__(self, lambda_: float, delta: float, *, include_bias: bool) -&gt; None:\n    \"\"\"Initialize the RLS Readout.\n\n    Args:\n        lambda_: Forgetting factor (0.0 to 1.0).\n        delta: Initial value for the covariance matrix diagonal.\n        include_bias: Whether to include a bias term.\n    \"\"\"\n    self.lambda_ = lambda_\n    self.delta = delta\n    self.include_bias = include_bias\n</code></pre>"},{"location":"api/#rclib.readouts.Lms","title":"<code>Lms</code>","text":"<p>Least Mean Squares (LMS) Readout configuration.</p> Source code in <code>python/rclib/readouts.py</code> <pre><code>class Lms:\n    \"\"\"Least Mean Squares (LMS) Readout configuration.\"\"\"\n\n    def __init__(self, learning_rate: float, *, include_bias: bool) -&gt; None:\n        \"\"\"Initialize the LMS Readout.\n\n        Args:\n            learning_rate: Learning rate for the LMS algorithm.\n            include_bias: Whether to include a bias term.\n        \"\"\"\n        self.learning_rate = learning_rate\n        self.include_bias = include_bias\n</code></pre>"},{"location":"api/#rclib.readouts.Lms.__init__","title":"<code>__init__(learning_rate, *, include_bias)</code>","text":"<p>Initialize the LMS Readout.</p> <p>Args:     learning_rate: Learning rate for the LMS algorithm.     include_bias: Whether to include a bias term.</p> Source code in <code>python/rclib/readouts.py</code> <pre><code>def __init__(self, learning_rate: float, *, include_bias: bool) -&gt; None:\n    \"\"\"Initialize the LMS Readout.\n\n    Args:\n        learning_rate: Learning rate for the LMS algorithm.\n        include_bias: Whether to include a bias term.\n    \"\"\"\n    self.learning_rate = learning_rate\n    self.include_bias = include_bias\n</code></pre>"},{"location":"api/#model","title":"Model","text":""},{"location":"api/#rclib.model","title":"<code>rclib.model</code>","text":"<p>Model module for Reservoir Computing.</p>"},{"location":"api/#rclib.model.ESN","title":"<code>ESN</code>","text":"<p>Echo State Network (ESN) model.</p> Source code in <code>python/rclib/model.py</code> <pre><code>class ESN:\n    \"\"\"Echo State Network (ESN) model.\"\"\"\n\n    def __init__(self, connection_type: str = \"serial\") -&gt; None:\n        \"\"\"Initialize the ESN model.\n\n        Parameters\n        ----------\n        connection_type : str, optional\n            The type of connection between reservoirs (\"serial\" or \"parallel\").\n            Default is \"serial\".\n        \"\"\"\n        self.connection_type = connection_type\n        self._reservoirs_params: list[Any] = []  # Store parameters for Python-side reservoir objects\n        self._readout_params: Any = None  # Store parameters for Python-side readout object\n        self._cpp_model = _rclib.Model()  # Initialize the C++ Model object\n\n    def add_reservoir(self, reservoir: Any) -&gt; None:  # noqa: ANN401\n        \"\"\"Add a reservoir to the model.\n\n        Parameters\n        ----------\n        reservoir : Any\n            The reservoir object to add.\n\n        Raises\n        ------\n        TypeError\n            If the reservoir type is unsupported.\n        \"\"\"\n        # Store the Python reservoir object's parameters\n        self._reservoirs_params.append(reservoir)\n        # Create and add the C++ reservoir to the C++ model\n        if isinstance(reservoir, reservoirs.RandomSparse):\n            cpp_res = _rclib.RandomSparseReservoir(\n                reservoir.n_neurons,\n                reservoir.spectral_radius,\n                reservoir.sparsity,\n                reservoir.leak_rate,\n                reservoir.input_scaling,\n                reservoir.include_bias,\n                reservoir.seed,\n            )\n            self._cpp_model.addReservoir(cpp_res, self.connection_type)\n        elif isinstance(reservoir, reservoirs.Nvar):\n            cpp_res = _rclib.NvarReservoir(reservoir.num_lags)\n            self._cpp_model.addReservoir(cpp_res, self.connection_type)\n        # Add other reservoir types here as they are implemented\n        else:\n            msg = \"Unsupported reservoir type\"\n            raise TypeError(msg)\n\n    def set_readout(self, readout: Any) -&gt; None:  # noqa: ANN401\n        \"\"\"Set the readout for the model.\n\n        Parameters\n        ----------\n        readout : Any\n            The readout object to set.\n\n        Raises\n        ------\n        TypeError\n            If the readout type is unsupported.\n        \"\"\"\n        # Store the Python readout object's parameters\n        self._readout_params = readout\n        # Create and set the C++ readout to the C++ model\n        if isinstance(readout, readouts.Ridge):\n            solver_map = {\n                \"cholesky\": _rclib.RidgeReadout.Solver.CHOLESKY,\n                \"conjugate_gradient\": _rclib.RidgeReadout.Solver.CONJUGATE_GRADIENT,\n                \"conjugate_gradient_implicit\": _rclib.RidgeReadout.Solver.CONJUGATE_GRADIENT_IMPLICIT,\n            }\n            if readout.solver not in solver_map:\n                msg = f\"Unsupported solver: {readout.solver}\"\n                raise ValueError(msg)\n\n            cpp_readout = _rclib.RidgeReadout(readout.alpha, readout.include_bias, solver_map[readout.solver])\n            self._cpp_model.setReadout(cpp_readout)\n        elif isinstance(readout, readouts.Rls):\n            cpp_readout = _rclib.RlsReadout(readout.lambda_, readout.delta, readout.include_bias)\n            self._cpp_model.setReadout(cpp_readout)\n        elif isinstance(readout, readouts.Lms):\n            cpp_readout = _rclib.LmsReadout(readout.learning_rate, readout.include_bias)\n            self._cpp_model.setReadout(cpp_readout)\n        else:\n            msg = \"Unsupported readout type\"\n            raise TypeError(msg)\n\n    def fit(self, x: ArrayLike, y: ArrayLike, washout_len: int = 0) -&gt; None:\n        \"\"\"Fit the model to the data.\n\n        Parameters\n        ----------\n        x : ArrayLike\n            Input data.\n        y : ArrayLike\n            Target data.\n        washout_len : int, optional\n            Number of initial samples to discard. Default is 0.\n        \"\"\"\n        # Call the C++ model's fit method\n        self._cpp_model.fit(x, y, washout_len)\n\n    def predict(self, x: ArrayLike, *, reset_state_before_predict: bool = True) -&gt; np.ndarray:\n        \"\"\"Predict using the trained model.\n\n        Parameters\n        ----------\n        x : ArrayLike\n            Input data.\n        reset_state_before_predict : bool, optional\n            Whether to reset the reservoir state before prediction. Default is True.\n\n        Returns\n        -------\n        np.ndarray\n            The predicted values.\n        \"\"\"\n        # Call the C++ model's predict method\n        return self._cpp_model.predict(x, reset_state_before_predict)\n\n    def predict_online(self, x: ArrayLike) -&gt; np.ndarray:\n        \"\"\"Predict in online mode (updating state).\n\n        Parameters\n        ----------\n        x : ArrayLike\n            Input data.\n\n        Returns\n        -------\n        np.ndarray\n            The predicted values.\n        \"\"\"\n        # Call the C++ model's predictOnline method\n        return self._cpp_model.predictOnline(x)\n\n    def predict_generative(self, prime_data: ArrayLike, n_steps: int) -&gt; np.ndarray:\n        \"\"\"Generative prediction.\n\n        Parameters\n        ----------\n        prime_data : ArrayLike\n            Initial data to prime the reservoir.\n        n_steps : int\n            Number of steps to generate.\n\n        Returns\n        -------\n        np.ndarray\n            The generated data.\n        \"\"\"\n        # Call the C++ model's predictGenerative method\n        return self._cpp_model.predictGenerative(prime_data, n_steps)\n\n    def get_reservoir(self, index: int) -&gt; Any:  # noqa: ANN401\n        \"\"\"Get the reservoir object at the specified index.\n\n        Parameters\n        ----------\n        index : int\n            The index of the reservoir.\n\n        Returns\n        -------\n        Any\n            The C++ reservoir object.\n        \"\"\"\n        # Return the C++ reservoir object\n        return self._cpp_model.getReservoir(index)\n\n    def reset_reservoirs(self) -&gt; None:\n        \"\"\"Reset the states of all reservoirs.\"\"\"\n        # Call the C++ model's resetReservoirs method\n        self._cpp_model.resetReservoirs()\n\n    def partial_fit(self, x: ArrayLike, y: ArrayLike) -&gt; None:\n        \"\"\"Update the model with a single sample (online learning).\n\n        Parameters\n        ----------\n        x : ArrayLike\n            Input data sample.\n        y : ArrayLike\n            Target data sample.\n\n        Raises\n        ------\n        RuntimeError\n            If no reservoir or readout is set.\n        \"\"\"\n        # Assuming only one reservoir for simplicity in online learning for now.\n        # If multiple reservoirs are present, the logic would need to be more complex\n        # to handle how their states are combined before feeding to the readout.\n        if not self._reservoirs_params:\n            msg = \"No reservoir added to the model.\"\n            raise RuntimeError(msg)\n        if not self._readout_params:\n            msg = \"No readout set for the model.\"\n            raise RuntimeError(msg)\n\n        # Get the C++ reservoir object (assuming the first one for now)\n        cpp_res = self._cpp_model.getReservoir(0)\n\n        # Advance reservoir state\n        cpp_res.advance(x)\n        current_state = cpp_res.getState()\n\n        # Get the C++ readout object\n        cpp_readout = self._cpp_model.getReadout()\n\n        # Perform partial fit (online update)\n        cpp_readout.partialFit(current_state, y)\n</code></pre>"},{"location":"api/#rclib.model.ESN.__init__","title":"<code>__init__(connection_type='serial')</code>","text":"<p>Initialize the ESN model.</p> <p>Parameters:</p> Name Type Description Default <code>connection_type</code> <code>str</code> <p>The type of connection between reservoirs (\"serial\" or \"parallel\"). Default is \"serial\".</p> <code>'serial'</code> Source code in <code>python/rclib/model.py</code> <pre><code>def __init__(self, connection_type: str = \"serial\") -&gt; None:\n    \"\"\"Initialize the ESN model.\n\n    Parameters\n    ----------\n    connection_type : str, optional\n        The type of connection between reservoirs (\"serial\" or \"parallel\").\n        Default is \"serial\".\n    \"\"\"\n    self.connection_type = connection_type\n    self._reservoirs_params: list[Any] = []  # Store parameters for Python-side reservoir objects\n    self._readout_params: Any = None  # Store parameters for Python-side readout object\n    self._cpp_model = _rclib.Model()  # Initialize the C++ Model object\n</code></pre>"},{"location":"api/#rclib.model.ESN.add_reservoir","title":"<code>add_reservoir(reservoir)</code>","text":"<p>Add a reservoir to the model.</p> <p>Parameters:</p> Name Type Description Default <code>reservoir</code> <code>Any</code> <p>The reservoir object to add.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If the reservoir type is unsupported.</p> Source code in <code>python/rclib/model.py</code> <pre><code>def add_reservoir(self, reservoir: Any) -&gt; None:  # noqa: ANN401\n    \"\"\"Add a reservoir to the model.\n\n    Parameters\n    ----------\n    reservoir : Any\n        The reservoir object to add.\n\n    Raises\n    ------\n    TypeError\n        If the reservoir type is unsupported.\n    \"\"\"\n    # Store the Python reservoir object's parameters\n    self._reservoirs_params.append(reservoir)\n    # Create and add the C++ reservoir to the C++ model\n    if isinstance(reservoir, reservoirs.RandomSparse):\n        cpp_res = _rclib.RandomSparseReservoir(\n            reservoir.n_neurons,\n            reservoir.spectral_radius,\n            reservoir.sparsity,\n            reservoir.leak_rate,\n            reservoir.input_scaling,\n            reservoir.include_bias,\n            reservoir.seed,\n        )\n        self._cpp_model.addReservoir(cpp_res, self.connection_type)\n    elif isinstance(reservoir, reservoirs.Nvar):\n        cpp_res = _rclib.NvarReservoir(reservoir.num_lags)\n        self._cpp_model.addReservoir(cpp_res, self.connection_type)\n    # Add other reservoir types here as they are implemented\n    else:\n        msg = \"Unsupported reservoir type\"\n        raise TypeError(msg)\n</code></pre>"},{"location":"api/#rclib.model.ESN.fit","title":"<code>fit(x, y, washout_len=0)</code>","text":"<p>Fit the model to the data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ArrayLike</code> <p>Input data.</p> required <code>y</code> <code>ArrayLike</code> <p>Target data.</p> required <code>washout_len</code> <code>int</code> <p>Number of initial samples to discard. Default is 0.</p> <code>0</code> Source code in <code>python/rclib/model.py</code> <pre><code>def fit(self, x: ArrayLike, y: ArrayLike, washout_len: int = 0) -&gt; None:\n    \"\"\"Fit the model to the data.\n\n    Parameters\n    ----------\n    x : ArrayLike\n        Input data.\n    y : ArrayLike\n        Target data.\n    washout_len : int, optional\n        Number of initial samples to discard. Default is 0.\n    \"\"\"\n    # Call the C++ model's fit method\n    self._cpp_model.fit(x, y, washout_len)\n</code></pre>"},{"location":"api/#rclib.model.ESN.get_reservoir","title":"<code>get_reservoir(index)</code>","text":"<p>Get the reservoir object at the specified index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>The index of the reservoir.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The C++ reservoir object.</p> Source code in <code>python/rclib/model.py</code> <pre><code>def get_reservoir(self, index: int) -&gt; Any:  # noqa: ANN401\n    \"\"\"Get the reservoir object at the specified index.\n\n    Parameters\n    ----------\n    index : int\n        The index of the reservoir.\n\n    Returns\n    -------\n    Any\n        The C++ reservoir object.\n    \"\"\"\n    # Return the C++ reservoir object\n    return self._cpp_model.getReservoir(index)\n</code></pre>"},{"location":"api/#rclib.model.ESN.partial_fit","title":"<code>partial_fit(x, y)</code>","text":"<p>Update the model with a single sample (online learning).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ArrayLike</code> <p>Input data sample.</p> required <code>y</code> <code>ArrayLike</code> <p>Target data sample.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If no reservoir or readout is set.</p> Source code in <code>python/rclib/model.py</code> <pre><code>def partial_fit(self, x: ArrayLike, y: ArrayLike) -&gt; None:\n    \"\"\"Update the model with a single sample (online learning).\n\n    Parameters\n    ----------\n    x : ArrayLike\n        Input data sample.\n    y : ArrayLike\n        Target data sample.\n\n    Raises\n    ------\n    RuntimeError\n        If no reservoir or readout is set.\n    \"\"\"\n    # Assuming only one reservoir for simplicity in online learning for now.\n    # If multiple reservoirs are present, the logic would need to be more complex\n    # to handle how their states are combined before feeding to the readout.\n    if not self._reservoirs_params:\n        msg = \"No reservoir added to the model.\"\n        raise RuntimeError(msg)\n    if not self._readout_params:\n        msg = \"No readout set for the model.\"\n        raise RuntimeError(msg)\n\n    # Get the C++ reservoir object (assuming the first one for now)\n    cpp_res = self._cpp_model.getReservoir(0)\n\n    # Advance reservoir state\n    cpp_res.advance(x)\n    current_state = cpp_res.getState()\n\n    # Get the C++ readout object\n    cpp_readout = self._cpp_model.getReadout()\n\n    # Perform partial fit (online update)\n    cpp_readout.partialFit(current_state, y)\n</code></pre>"},{"location":"api/#rclib.model.ESN.predict","title":"<code>predict(x, *, reset_state_before_predict=True)</code>","text":"<p>Predict using the trained model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ArrayLike</code> <p>Input data.</p> required <code>reset_state_before_predict</code> <code>bool</code> <p>Whether to reset the reservoir state before prediction. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The predicted values.</p> Source code in <code>python/rclib/model.py</code> <pre><code>def predict(self, x: ArrayLike, *, reset_state_before_predict: bool = True) -&gt; np.ndarray:\n    \"\"\"Predict using the trained model.\n\n    Parameters\n    ----------\n    x : ArrayLike\n        Input data.\n    reset_state_before_predict : bool, optional\n        Whether to reset the reservoir state before prediction. Default is True.\n\n    Returns\n    -------\n    np.ndarray\n        The predicted values.\n    \"\"\"\n    # Call the C++ model's predict method\n    return self._cpp_model.predict(x, reset_state_before_predict)\n</code></pre>"},{"location":"api/#rclib.model.ESN.predict_generative","title":"<code>predict_generative(prime_data, n_steps)</code>","text":"<p>Generative prediction.</p> <p>Parameters:</p> Name Type Description Default <code>prime_data</code> <code>ArrayLike</code> <p>Initial data to prime the reservoir.</p> required <code>n_steps</code> <code>int</code> <p>Number of steps to generate.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The generated data.</p> Source code in <code>python/rclib/model.py</code> <pre><code>def predict_generative(self, prime_data: ArrayLike, n_steps: int) -&gt; np.ndarray:\n    \"\"\"Generative prediction.\n\n    Parameters\n    ----------\n    prime_data : ArrayLike\n        Initial data to prime the reservoir.\n    n_steps : int\n        Number of steps to generate.\n\n    Returns\n    -------\n    np.ndarray\n        The generated data.\n    \"\"\"\n    # Call the C++ model's predictGenerative method\n    return self._cpp_model.predictGenerative(prime_data, n_steps)\n</code></pre>"},{"location":"api/#rclib.model.ESN.predict_online","title":"<code>predict_online(x)</code>","text":"<p>Predict in online mode (updating state).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ArrayLike</code> <p>Input data.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The predicted values.</p> Source code in <code>python/rclib/model.py</code> <pre><code>def predict_online(self, x: ArrayLike) -&gt; np.ndarray:\n    \"\"\"Predict in online mode (updating state).\n\n    Parameters\n    ----------\n    x : ArrayLike\n        Input data.\n\n    Returns\n    -------\n    np.ndarray\n        The predicted values.\n    \"\"\"\n    # Call the C++ model's predictOnline method\n    return self._cpp_model.predictOnline(x)\n</code></pre>"},{"location":"api/#rclib.model.ESN.reset_reservoirs","title":"<code>reset_reservoirs()</code>","text":"<p>Reset the states of all reservoirs.</p> Source code in <code>python/rclib/model.py</code> <pre><code>def reset_reservoirs(self) -&gt; None:\n    \"\"\"Reset the states of all reservoirs.\"\"\"\n    # Call the C++ model's resetReservoirs method\n    self._cpp_model.resetReservoirs()\n</code></pre>"},{"location":"api/#rclib.model.ESN.set_readout","title":"<code>set_readout(readout)</code>","text":"<p>Set the readout for the model.</p> <p>Parameters:</p> Name Type Description Default <code>readout</code> <code>Any</code> <p>The readout object to set.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If the readout type is unsupported.</p> Source code in <code>python/rclib/model.py</code> <pre><code>def set_readout(self, readout: Any) -&gt; None:  # noqa: ANN401\n    \"\"\"Set the readout for the model.\n\n    Parameters\n    ----------\n    readout : Any\n        The readout object to set.\n\n    Raises\n    ------\n    TypeError\n        If the readout type is unsupported.\n    \"\"\"\n    # Store the Python readout object's parameters\n    self._readout_params = readout\n    # Create and set the C++ readout to the C++ model\n    if isinstance(readout, readouts.Ridge):\n        solver_map = {\n            \"cholesky\": _rclib.RidgeReadout.Solver.CHOLESKY,\n            \"conjugate_gradient\": _rclib.RidgeReadout.Solver.CONJUGATE_GRADIENT,\n            \"conjugate_gradient_implicit\": _rclib.RidgeReadout.Solver.CONJUGATE_GRADIENT_IMPLICIT,\n        }\n        if readout.solver not in solver_map:\n            msg = f\"Unsupported solver: {readout.solver}\"\n            raise ValueError(msg)\n\n        cpp_readout = _rclib.RidgeReadout(readout.alpha, readout.include_bias, solver_map[readout.solver])\n        self._cpp_model.setReadout(cpp_readout)\n    elif isinstance(readout, readouts.Rls):\n        cpp_readout = _rclib.RlsReadout(readout.lambda_, readout.delta, readout.include_bias)\n        self._cpp_model.setReadout(cpp_readout)\n    elif isinstance(readout, readouts.Lms):\n        cpp_readout = _rclib.LmsReadout(readout.learning_rate, readout.include_bias)\n        self._cpp_model.setReadout(cpp_readout)\n    else:\n        msg = \"Unsupported readout type\"\n        raise TypeError(msg)\n</code></pre>"},{"location":"development/","title":"Development Guide","text":"<p>This section is for contributors who want to modify or extend <code>rclib</code>.</p>"},{"location":"development/#project-goals","title":"Project Goals","text":"<ul> <li>Performance: Core logic in C++17 using Eigen.</li> <li>Scalability: Efficient handling of large sparse reservoirs.</li> <li>Modularity: Clear separation between Reservoirs and Readouts.</li> </ul>"},{"location":"development/#setup","title":"Setup","text":"<ol> <li>Install <code>uv</code>: We use <code>uv</code> for dependency management.</li> <li>Clone recursively: <code>git clone --recursive ...</code></li> <li>Sync environment: <code>uv sync</code></li> </ol>"},{"location":"development/#workflow","title":"Workflow","text":""},{"location":"development/#code-quality","title":"Code Quality","text":"<p>We use <code>pre-commit</code> to enforce standards.</p> <pre><code>uv run pre-commit install\n</code></pre> <p>Tools used: *   <code>ruff</code> (Python linting/formatting) *   <code>basedpyright</code> (Static type checking) *   <code>clang-format</code> (C++ formatting)</p>"},{"location":"development/#running-tests","title":"Running Tests","text":"<p>C++ Unit Tests: <pre><code>cmake -S . -B build -DBUILD_TESTING=ON\ncmake --build build --config Release\nctest --test-dir build\n</code></pre></p> <p>Python Integration Tests: <pre><code># Ensure library is built\ncmake -S . -B build\ncmake --build build --config Release -j $(nproc) --target _rclib\n# Run pytest\nuv run pytest\n</code></pre></p>"},{"location":"development/#documentation","title":"Documentation","text":"<ul> <li>Release Process: How to publish a new version.</li> <li>Testing Roadmap: Plans for future test coverage.</li> <li>RLS Optimization Report: Detailed report on RLS performance improvements.</li> </ul>"},{"location":"development/release_process/","title":"Release Process","text":"<p>This document outlines the steps required to create a new release of <code>rclib</code>, including publishing to PyPI and updating the documentation.</p>"},{"location":"development/release_process/#prerequisites","title":"Prerequisites","text":"<ol> <li>Permissions: You must have write access to the GitHub repository and be configured as a Trusted Publisher on PyPI for this repository.</li> <li>Environment: Ensure all tests pass locally using <code>uv run nox</code>.</li> </ol>"},{"location":"development/release_process/#step-by-step-guide","title":"Step-by-Step Guide","text":""},{"location":"development/release_process/#1-update-version-number","title":"1. Update Version Number","text":"<p>Use the provided script to increment the version in <code>pyproject.toml</code>, sync the lockfile, and create a git commit and tag automatically.</p> <pre><code># Choose one based on the change type\n./scripts/bump_version.sh patch\n# or\n./scripts/bump_version.sh minor\n# or\n./scripts/bump_version.sh major\n</code></pre>"},{"location":"development/release_process/#2-push-to-github","title":"2. Push to GitHub","text":"<p>After the script completes, push the new commit and tag to GitHub.</p> <pre><code>git push origin main --atomic --follow-tags\n</code></pre>"},{"location":"development/release_process/#3-review-the-release-draft","title":"3. Review the Release Draft","text":"<p>Pushing a tag starting with <code>v*</code> automatically triggers the Create Release Draft workflow.</p> <ol> <li>Go to the Releases section of the GitHub repository.</li> <li>Find the new draft release.</li> <li>Review the automatically generated release notes.</li> <li>Click Edit to add any manual highlights or breaking change notices.</li> <li>Click Publish release.</li> </ol>"},{"location":"development/release_process/#4-automated-publishing","title":"4. Automated Publishing","text":"<p>Once the release is published on GitHub, the Publish to PyPI workflow triggers automatically:</p> <ul> <li>It checks out the code (including submodules).</li> <li>It builds the source distribution (<code>.tar.gz</code>).</li> <li>It builds manylinux-compliant binary wheels for multiple Python versions (3.11, 3.12, 3.13) using <code>cibuildwheel</code>.</li> <li>It securely uploads all artifacts to PyPI using OpenID Connect (OIDC).</li> </ul>"},{"location":"development/release_process/#5-documentation-deployment","title":"5. Documentation Deployment","text":"<p>The documentation is automatically deployed to GitHub Pages whenever changes are merged into the <code>main</code> branch. If your release involved merging into <code>main</code>, your documentation at https://hrshtst.github.io/rclib/ will be updated.</p>"},{"location":"development/release_process/#versioning-policy","title":"Versioning Policy","text":"<p><code>rclib</code> follows Semantic Versioning (SemVer): *   MAJOR version for incompatible API changes. *   MINOR version for add functionality in a backwards compatible manner. *   PATCH version for backwards compatible bug fixes.</p>"},{"location":"development/testing_roadmap/","title":"Testing &amp; Quality Roadmap","text":"<p>This document outlines the planned expansion of the integration and regression test suite for <code>rclib</code>. These tests aim to ensure mathematical correctness, architectural robustness, and numerical stability as the library evolves.</p>"},{"location":"development/testing_roadmap/#1-nvar-pipeline-integration","title":"1. NVAR Pipeline Integration","text":"<p>While unit tests exist for the <code>NvarReservoir</code> class, a full model-level integration test is needed. *   Target: Next-Generation Reservoir Computing (NVAR) architecture. *   Test Scenario: Train an NVAR-based model on a chaotic system (e.g., Lorenz Attractor). *   Verification: Ensure the model correctly constructs the non-linear feature vector and achieves a low MSE without random weight matrices.</p>"},{"location":"development/testing_roadmap/#2-generative-stability","title":"2. Generative Stability","text":"<p>Generative prediction (closed-loop) is sensitive to accumulated errors. *   Target: <code>predict_generative</code> method. *   Test Scenario: Train on a stable periodic signal, then generate 1000+ steps autonomously. *   Verification: Assert that the generated signal remains within a valid range (e.g., \\([-2, 2]\\)) and maintains the target frequency without diverging or decaying to zero.</p>"},{"location":"development/testing_roadmap/#3-deep-esn-architecture-serial","title":"3. Deep ESN Architecture (Serial)","text":"<p>Verifying the stacking logic for deep networks. *   Target: <code>serial</code> connection type in the <code>Model</code> class. *   Test Scenario: Create a stack of 3+ reservoirs where the state of \\(Res_n\\) serves as the input to \\(Res_{n+1}\\). *   Verification: Confirm that state propagation and concatenation are handled correctly and that the model achieves better performance on complex tasks compared to a shallow reservoir of the same total size.</p>"},{"location":"development/testing_roadmap/#4-multidimensional-io-robustness","title":"4. Multidimensional I/O Robustness","text":"<p>Ensuring consistent handling of high-dimensional data across the C++/Python boundary. *   Target: Linear algebra and data-passing logic. *   Test Scenario: Implement a \"Multiple-Input Multiple-Output\" (MIMO) task with 5D input and 5D target vectors. *   Verification: Validate that matrix dimensions, transpositions, and indexing are correctly handled for non-scalar time series.</p>"},{"location":"development/testing_roadmap/#5-numerical-edge-cases-stress-testing","title":"5. Numerical Edge Cases &amp; Stress Testing","text":"<p>Testing the library's resilience to extreme parameters. *   Target: Error handling and stability. *   Test Scenario:     *   Large spectral radius (\\(&gt; 1.0\\)) leading to saturation.     *   Small RLS forgetting factors causing potential matrix ill-conditioning.     *   Zero-length or empty input data. *   Verification: Ensure the library throws meaningful exceptions (via <code>std::runtime_error</code>) or remains stable through regularization, rather than crashing or returning <code>NaN</code>.</p>"},{"location":"development/testing_roadmap/#6-performance-benchmarking-regression","title":"6. Performance Benchmarking Regression","text":"<ul> <li>Target: Computational efficiency.</li> <li>Test Scenario: Measure execution time for fitting a large-scale reservoir.</li> <li>Verification: Establish a baseline and assert that new commits do not deviate by more than 10% from the baseline time on identical CI hardware.</li> </ul>"},{"location":"development/reports/RLS_Optimization_Report/","title":"RLS Optimization Report","text":"<p>Date: December 4, 2025 Author: Gemini Agent</p>"},{"location":"development/reports/RLS_Optimization_Report/#executive-summary","title":"Executive Summary","text":"<p>This report details the optimizations applied to the Recursive Least Squares (RLS) online learning algorithm within <code>rclib</code>. The primary goal was to improve the computational performance of the <code>RlsReadout::partialFit</code> method, which is critical for real-time applications.</p> <p>Result: A ~5.5x speedup was achieved in the <code>online_rls</code> benchmark (decreasing execution time from 14.06s to 2.54s) without compromising numerical accuracy.</p>"},{"location":"development/reports/RLS_Optimization_Report/#mathematical-formulation","title":"Mathematical Formulation","text":"<p>The standard RLS update equations used were:</p> <ol> <li>Gain Calculation:     $$ \\mathbf{k} = \\frac{\\mathbf{P} \\mathbf{x}}{ \\lambda + \\mathbf{x}^T \\mathbf{P} \\mathbf{x} } $$</li> <li>Weight Update:     $$ \\mathbf{W} \\leftarrow \\mathbf{W} + \\mathbf{k} \\mathbf{e}^T $$     where \\(\\mathbf{e} = \\mathbf{d} - \\mathbf{W}^T \\mathbf{x}\\) is the prediction error.</li> <li>Covariance Matrix Update:     $$ \\mathbf{P} \\leftarrow \\lambda^{-1} (\\mathbf{P} - \\mathbf{k} \\mathbf{x}^T \\mathbf{P}) $$</li> </ol>"},{"location":"development/reports/RLS_Optimization_Report/#optimization-symmetric-rank-1-update-previous-summary","title":"Optimization: Symmetric Rank-1 Update (Previous Summary)","text":"<p>Since \\(\\mathbf{P}\\) is a symmetric matrix (Inverse Covariance Matrix), we can optimize step 3. Note that \\(\\mathbf{k} = \\frac{\\mathbf{P}\\mathbf{x}}{D}\\) where \\(D = \\lambda + \\mathbf{x}^T \\mathbf{P} \\mathbf{x}\\).</p> <p>Substituting \\(\\mathbf{k}\\): $$ \\mathbf{k} \\mathbf{x}^T \\mathbf{P} = \\frac{\\mathbf{P}\\mathbf{x} (\\mathbf{P}\\mathbf{x})^T}{D} $$</p> <p>Thus the update becomes a symmetric rank-1 update: $$ \\mathbf{P} \\leftarrow \\lambda^{-1} \\left( \\mathbf{P} - \\frac{(\\mathbf{P}\\mathbf{x})(\\mathbf{P}\\mathbf{x})^T}{D} \\right) $$</p> <p>In Eigen, this allows us to use the highly optimized <code>rankUpdate</code> method on a <code>selfadjointView</code>, which only computes and updates the upper triangular part of the matrix, reducing FLOPs by approximately 50%.</p>"},{"location":"development/reports/RLS_Optimization_Report/#detailed-explanation-of-symmetric-rank-1-update","title":"Detailed Explanation of Symmetric Rank-1 Update","text":"<p>The <code>P</code> matrix in RLS represents the inverse covariance matrix, which is inherently symmetric. This property can be leveraged for significant performance gains.</p>"},{"location":"development/reports/RLS_Optimization_Report/#1-the-concept-of-a-rank-1-update","title":"1. The Concept of a Rank-1 Update","text":"<p>A Rank-1 update modifies a matrix \\(\\mathbf{A}\\) by adding the outer product of two vectors, \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\): $$ \\mathbf{A}{new} = \\mathbf{A} + \\alpha \\mathbf{u} \\mathbf{v}^T $$ If \\(\\mathbf{u} = \\mathbf{v}\\), the update is Symmetric: $$ \\mathbf{A}{new} = \\mathbf{A} + \\alpha \\mathbf{v} \\mathbf{v}^T $$ This operation maintains the symmetry of the matrix \\(\\mathbf{A}\\).</p>"},{"location":"development/reports/RLS_Optimization_Report/#2-mathematical-derivation-in-rls","title":"2. Mathematical Derivation in RLS","text":"<p>Let's re-examine the RLS covariance update (step 3): $$ \\mathbf{P}_{new} = \\frac{1}{\\lambda} (\\mathbf{P} - \\mathbf{k} \\mathbf{x}^T \\mathbf{P}) $$ The gain vector \\(\\mathbf{k}\\) is defined as: $$ \\mathbf{k} = \\frac{\\mathbf{P} \\mathbf{x}}{\\lambda + \\mathbf{x}^T \\mathbf{P} \\mathbf{x}} $$ Let \\(\\mathbf{v} = \\mathbf{P} \\mathbf{x}\\) and \\(D = \\lambda + \\mathbf{x}^T \\mathbf{P} \\mathbf{x}\\). Then \\(\\mathbf{k} = \\frac{\\mathbf{v}}{D}\\). Since \\(\\mathbf{P}\\) is symmetric (\\(\\mathbf{P} = \\mathbf{P}^T\\)), we know that \\(\\mathbf{x}^T \\mathbf{P} = (\\mathbf{P} \\mathbf{x})^T = \\mathbf{v}^T\\).</p> <p>Substituting these into the subtraction term: $$ \\mathbf{k} (\\mathbf{x}^T \\mathbf{P}) = \\left( \\frac{\\mathbf{v}}{D} \\right) \\mathbf{v}^T = \\frac{1}{D} \\mathbf{v} \\mathbf{v}^T $$ This clearly shows that the term being subtracted from \\(\\mathbf{P}\\) is a symmetric rank-1 matrix formed by \\(\\frac{1}{D} (\\mathbf{P}\\mathbf{x})(\\mathbf{P}\\mathbf{x})^T\\).</p> <p>Thus, the optimized covariance matrix update becomes: $$ \\mathbf{P} \\leftarrow \\lambda^{-1} \\left( \\mathbf{P} - \\frac{(\\mathbf{P}\\mathbf{x})(\\mathbf{P}\\mathbf{x})^T}{\\lambda + \\mathbf{x}^T \\mathbf{P} \\mathbf{x}} \\right) $$</p>"},{"location":"development/reports/RLS_Optimization_Report/#3-computational-advantages","title":"3. Computational Advantages","text":"<p>Exploiting this symmetric rank-1 structure offers significant performance benefits:</p> <ul> <li>Reduced FLOPs: For an \\(N \\times N\\) matrix, a full update typically involves \\(O(N^2)\\) operations. By only computing and updating the unique elements (e.g., the upper or lower triangular part), the number of floating-point operations can be reduced by nearly 50% (from \\(N^2\\) to \\(\\frac{N(N+1)}{2}\\)).</li> <li>Improved Memory Access: Modifying only half of the matrix significantly reduces memory read/write traffic, which can be a major bottleneck for large matrices that don't fit entirely into CPU caches.</li> <li>Optimized Library Functions: Linear algebra libraries like Eigen provide highly optimized functions for symmetric rank-1 updates (e.g., <code>Eigen::SelfAdjointView::rankUpdate</code>). These functions are often implemented using specialized algorithms and CPU intrinsics (like AVX/SSE) that are much faster than general matrix operations.</li> </ul> <p>In the <code>rclib</code> implementation, this was achieved by using <code>P.selfadjointView&lt;Eigen::Upper&gt;().rankUpdate(Px, -1.0 / (lambda * denominator));</code> combined with an initial scaling of <code>P.triangularView&lt;Eigen::Upper&gt;() *= (1.0 / lambda);</code>.</p>"},{"location":"development/reports/RLS_Optimization_Report/#codebase-diffs","title":"Codebase Diffs","text":""},{"location":"development/reports/RLS_Optimization_Report/#1-header-file-cpp_coreincluderclibreadoutsrlsreadouth","title":"1. Header File (<code>cpp_core/include/rclib/readouts/RlsReadout.h</code>)","text":"<p>Change: Added pre-allocated temporary variables to avoid heap allocations during every <code>partialFit</code> call.</p> <pre><code>--- Old\n+++ New\n@@ -13,5 +13,11 @@\n     Eigen::MatrixXd W_out; // Weight matrix\n     Eigen::MatrixXd P;     // Inverse covariance matrix\n     bool initialized;\n+\n+    // Pre-allocated temporaries to avoid reallocation in partialFit\n+    Eigen::VectorXd x_aug;\n+    Eigen::VectorXd k;\n+    Eigen::VectorXd Px;\n+    Eigen::RowVectorXd xP; // (Unused in final optimized version but kept for structure)\n };\n</code></pre>"},{"location":"development/reports/RLS_Optimization_Report/#2-source-file-cpp_coresrcreadoutsrlsreadoutcpp","title":"2. Source File (<code>cpp_core/src/readouts/RlsReadout.cpp</code>)","text":"<p>Change: Refactored <code>partialFit</code> to use pre-allocated buffers, remove resizing, and utilize Eigen's <code>selfadjointView</code> for symmetric updates.</p> <pre><code>--- Old\n+++ New\n@@ -17,12 +17,13 @@\n\n void RlsReadout::partialFit(const Eigen::MatrixXd&amp; state, const Eigen::MatrixXd&amp; target) {\n     Eigen::MatrixXd x = state;\n-    if (include_bias) {\n-        x.conservativeResize(1, x.cols() + 1);\n-        x(0, x.cols() - 1) = 1.0;\n-    }\n+    // ... Initialization of x_aug and buffers (omitted for brevity) ...\n\n     // RLS update equations\n-    Eigen::MatrixXd Px = P * x.transpose();\n-    double denominator = lambda + (x * Px)(0,0);\n-    Eigen::MatrixXd k = Px / denominator;\n-    Eigen::MatrixXd y_hat = x * W_out;\n-    Eigen::MatrixXd error = target - y_hat;\n-\n-    W_out = W_out + k * error;\n-\n-    // Optimized P update: (1.0 / lambda) * (P - k * (x * P))\n-    Eigen::MatrixXd xP = x * P;\n-    P = (1.0 / lambda) * (P - k * xP);\n+\n+    // 1. Compute Px = P * x using symmetry (Upper triangle)\n+    Px.noalias() = P.selfadjointView&lt;Eigen::Upper&gt;() * x_aug;\n+\n+    // 2. Compute denominator = lambda + x^T * Px\n+    double denominator = lambda + x_aug.dot(Px);\n+\n+    // 3. Compute Kalman gain vector k = Px / denominator\n+    k = Px / denominator;\n+\n+    // 4. Compute prediction y_hat = x^T * W_out and error\n+    Eigen::MatrixXd error = target - (x_aug.transpose() * W_out);\n+\n+    // 5. Update weights: W_out = W_out + k * error\n+    W_out.noalias() += k * error;\n+\n+    // 6. Update P: P = (1/lambda) * (P - (Px * Px^T) / denominator)\n+    // Scale P\n+    P.triangularView&lt;Eigen::Upper&gt;() *= (1.0 / lambda);\n+    // Apply rank-1 update\n+    P.selfadjointView&lt;Eigen::Upper&gt;().rankUpdate(Px, -1.0 / (lambda * denominator));\n }\n</code></pre>"},{"location":"development/reports/RLS_Optimization_Report/#performance-benchmark","title":"Performance Benchmark","text":"<p>Benchmarks were run on the <code>mackey_glass</code> time-series prediction task using the <code>performance_benchmark.cpp</code> executable.</p> Metric Before Optimization After Optimization Improvement Time (s) 14.06s 2.54s 5.5x Faster MSE 0.000213 0.000215 Negligible Diff <p>The optimizations successfully removed the bottleneck in the online learning loop, making RLS a viable option for high-frequency updates.</p>"},{"location":"development/reports/Reservoir_Optimization_Report/","title":"Reservoir Performance Optimization Report","text":"<p>Date: February 3, 2026 Author: Gemini Agent</p>"},{"location":"development/reports/Reservoir_Optimization_Report/#executive-summary","title":"Executive Summary","text":"<p>This report details the optimization of the <code>RandomSparseReservoir::advance</code> method and the underlying matrix operations in <code>rclib</code>. The goal was to address performance bottlenecks identified when comparing <code>rclib</code> against <code>reservoirpy</code>.</p> <p>Result: A ~2.5x to 3x speedup was achieved in prediction times, making <code>rclib</code> consistently faster than <code>reservoirpy</code> across tested reservoir sizes (500 to 2000 neurons).</p>"},{"location":"development/reports/Reservoir_Optimization_Report/#optimization-details","title":"Optimization Details","text":""},{"location":"development/reports/Reservoir_Optimization_Report/#1-zero-copy-state-advancement","title":"1. Zero-Copy State Advancement","text":"<p>Problem: The <code>Reservoir::advance</code> method previously returned <code>Eigen::MatrixXd</code> by value. <pre><code>virtual Eigen::MatrixXd advance(const Eigen::MatrixXd &amp;input);\n</code></pre> This forced a deep copy of the entire state vector (size \\(1 \\times N\\)) at every single time step. For a sequence of length \\(T\\), this resulted in \\(T\\) unnecessary allocations and copies.</p> <p>Solution: The signature was updated to return a const reference to the internal state. <pre><code>virtual const Eigen::MatrixXd &amp;advance(const Eigen::MatrixXd &amp;input);\n</code></pre> This simple change eliminated significant memory bandwidth pressure.</p>"},{"location":"development/reports/Reservoir_Optimization_Report/#2-manual-sparse-matrix-multiplication","title":"2. Manual Sparse Matrix Multiplication","text":"<p>Problem: The state update involved multiplying a dense row vector (state) by a sparse matrix (weights): <code>state * W_res</code>. While <code>Eigen</code> handles this generically, the standard operator overloads for <code>Dense * Sparse</code> can sometimes incur overhead or fail to optimally exploit the specific sparsity pattern (Compressed Sparse Column - CSC) when the left-hand side is a vector.</p> <p>Solution: We replaced the generic Eigen expression with a manually optimized loop. Since <code>W_res</code> is stored in CSC format, iterating over its columns allows for efficient access to non-zero elements.</p> <p>The update logic \\(x_{new}[j] += \\sum_i x_{old}[i] \\cdot W_{ij}\\) was implemented using raw pointer access and explicit iteration over Eigen's <code>InnerIterator</code>:</p> <pre><code>const double *state_ptr = state.data();\ndouble *temp_ptr = temp_state.data();\n\nfor (int j = 0; j &lt; n_neurons; ++j) {\n  double dot = 0.0;\n  for (Eigen::SparseMatrix&lt;double&gt;::InnerIterator it(W_res, j); it; ++it) {\n    // it.index() is the row index (i), it.value() is W_{ij}\n    dot += state_ptr[it.index()] * it.value();\n  }\n  temp_ptr[j] += dot;\n}\n</code></pre>"},{"location":"development/reports/Reservoir_Optimization_Report/#3-memory-reuse-temp_state","title":"3. Memory Reuse (<code>temp_state</code>)","text":"<p>Problem: The intermediate calculation for the linear activation (before the non-linearity) required a temporary buffer. Previously, this was allocated dynamically inside the <code>advance</code> function every call.</p> <p>Solution: A <code>temp_state</code> member variable was added to the <code>RandomSparseReservoir</code> class. It is pre-allocated and resized only once (or when dimensions change), reusing the same memory block for all subsequent time steps.</p>"},{"location":"development/reports/Reservoir_Optimization_Report/#4-optimized-parallelization-strategy","title":"4. Optimized Parallelization Strategy","text":"<p>Problem: Initial attempts to parallelize the inner loop (neurons) using OpenMP (<code>#pragma omp parallel for</code>) resulted in a massive performance degradation (approx. 100x slower for N=1000).</p> <p>Analysis: For typical reservoir sizes (N=500 to 2000), the work per thread in a sparse matrix-vector product is very low. The overhead of spawning threads and, more importantly, the synchronization required (even implicit barriers), vastly outweighed the computational cost of the dot products.</p> <p>Solution: Inner-loop parallelization was re-introduced but strictly gated: 1.  Thresholding: Parallelization is only enabled for \\(N &gt; 1000\\). 2.  No Oversubscription: A check for <code>!omp_in_parallel()</code> ensures that if the reservoir is part of a parallel ensemble (already threaded), it runs serially to avoid thread explosion.</p> <p>The library now combines: 1.  Fine-Grained Parallelism: Multi-threaded updates for large single reservoirs. 2.  Course-Grained Parallelism: Parallelizing at the <code>Model</code> level for ensembles. 3.  Vectorization: Efficient sequential loops for small reservoirs (\\(N \\le 1000\\)).</p>"},{"location":"development/reports/Reservoir_Optimization_Report/#performance-benchmark","title":"Performance Benchmark","text":"<p>Benchmarks were conducted using the Mackey-Glass time series prediction task (\\(T=8000\\) steps).</p>"},{"location":"development/reports/Reservoir_Optimization_Report/#prediction-time-seconds","title":"Prediction Time (seconds)","text":"Neurons (\\(N\\)) <code>rclib</code> (Before) <code>rclib</code> (After) <code>reservoirpy</code> Speedup vs Old Status 500 0.203s 0.097s 0.274s ~2.1x Faster 1000 0.730s 0.296s 0.384s ~2.5x Faster 2000 3.105s 1.225s 1.288s ~2.5x Faster"},{"location":"development/reports/Reservoir_Optimization_Report/#training-time-seconds","title":"Training Time (seconds)","text":"<p>Training time (including <code>fit</code>) also improved significantly due to the faster state harvesting phase.</p> Neurons (\\(N\\)) <code>rclib</code> (Before) <code>rclib</code> (After) <code>reservoirpy</code> 2000 28.52s 18.76s 22.05s"},{"location":"development/reports/Reservoir_Optimization_Report/#conclusion","title":"Conclusion","text":"<p>By moving to low-level manual optimization for critical inner loops and eliminating unnecessary memory traffic, <code>rclib</code> now offers competitive performance for Reservoir Computing tasks in Python, providing significant speedups over <code>reservoirpy</code> in our benchmarks.</p>"},{"location":"theory/","title":"Theory","text":"<p>This section covers the mathematical foundations of the algorithms implemented in <code>rclib</code>.</p>"},{"location":"theory/#sections","title":"Sections","text":"<ul> <li>Reservoir Computing Overview: Introduction to RC and Echo State Networks.</li> <li>Readout Algorithms: Details on Ridge Regression, RLS, and LMS.</li> </ul>"},{"location":"theory/readout_algorithms/","title":"Readout Algorithms","text":"<p>The readout layer maps the reservoir state \\(\\mathbf{x}(t)\\) to the output \\(\\mathbf{y}(t)\\).</p> \\[ \\mathbf{y}(t) = \\mathbf{W}_{out} \\mathbf{x}(t) \\]"},{"location":"theory/readout_algorithms/#ridge-regression-batch","title":"Ridge Regression (Batch)","text":"<p>For batch training, we solve for \\(\\mathbf{W}_{out}\\) that minimizes the squared error with \\(L_2\\) regularization:</p> \\[ \\mathbf{W}_{out} = \\mathbf{Y}_{target} \\mathbf{X}^T (\\mathbf{X}\\mathbf{X}^T + \\alpha \\mathbf{I})^{-1} \\] <p>Where \\(\\mathbf{X}\\) collects all state vectors over time, and \\(\\alpha\\) is the regularization parameter.</p>"},{"location":"theory/readout_algorithms/#recursive-least-squares-rls-online","title":"Recursive Least Squares (RLS) (Online)","text":"<p>RLS updates the weights recursively for each new data point. It maintains an inverse covariance matrix \\(\\mathbf{P}\\).</p> <ol> <li>Gain Calculation:     $$ \\mathbf{k} = \\frac{\\mathbf{P} \\mathbf{x}}{ \\lambda + \\mathbf{x}^T \\mathbf{P} \\mathbf{x} } $$</li> <li>Weight Update:     $$ \\mathbf{W} \\leftarrow \\mathbf{W} + \\mathbf{k} \\mathbf{e}^T $$     where \\(\\mathbf{e} = \\mathbf{d} - \\mathbf{W}^T \\mathbf{x}\\) is the prediction error.</li> <li>Covariance Matrix Update:     $$ \\mathbf{P} \\leftarrow \\lambda^{-1} (\\mathbf{P} - \\mathbf{k} \\mathbf{x}^T \\mathbf{P}) $$</li> </ol> <p><code>rclib</code> implements an optimized version of the covariance update using symmetric rank-1 updates to significantly reduce computational cost:</p> \\[ \\mathbf{P} \\leftarrow \\lambda^{-1} \\left( \\mathbf{P} - \\frac{(\\mathbf{P}\\mathbf{x})(\\mathbf{P}\\mathbf{x})^T}{\\lambda + \\mathbf{x}^T \\mathbf{P} \\mathbf{x}} \\right) \\]"},{"location":"theory/readout_algorithms/#least-mean-squares-lms-online","title":"Least Mean Squares (LMS) (Online)","text":"<p>LMS is a stochastic gradient descent method.</p> \\[ \\mathbf{W} \\leftarrow \\mathbf{W} + \\eta \\mathbf{e} \\mathbf{x}^T \\] <p>Where \\(\\eta\\) is the learning rate. It is computationally cheaper (\\(O(N)\\)) than RLS (\\(O(N^2)\\)) but typically converges slower.</p>"},{"location":"theory/reservoir_computing/","title":"Reservoir Computing Overview","text":"<p>Reservoir Computing (RC) is a framework for training Recurrent Neural Networks (RNNs) where the recurrent part (the \"reservoir\") is fixed, and only the output weights are trained. This allows for extremely fast training compared to traditional Backpropagation Through Time (BPTT).</p>"},{"location":"theory/reservoir_computing/#echo-state-networks-esn","title":"Echo State Networks (ESN)","text":"<p>The standard Echo State Network (ESN) update equation is:</p> \\[ \\mathbf{x}(t+1) = (1-\\alpha)\\mathbf{x}(t) + \\alpha \\tanh(\\mathbf{W}_{in}\\mathbf{u}(t+1) + \\mathbf{W}_{res}\\mathbf{x}(t)) \\] <p>Where: *   \\(\\mathbf{x}(t)\\) is the reservoir state vector. *   \\(\\mathbf{u}(t)\\) is the input vector. *   \\(\\mathbf{W}_{in}\\) is the input weight matrix. *   \\(\\mathbf{W}_{res}\\) is the reservoir weight matrix. *   \\(\\alpha\\) is the leaking rate (\\(\\alpha \\in (0, 1]\\)).</p>"},{"location":"user_guide/","title":"User Guide","text":"<p>Welcome to the <code>rclib</code> User Guide. This guide will help you install the library, understand its core concepts, and build reservoir computing models for your applications.</p>"},{"location":"user_guide/#introduction","title":"Introduction","text":"<p><code>rclib</code> is a C++ based Reservoir Computing library with Python bindings. It offers high performance for training large-scale Echo State Networks (ESNs) and related architectures.</p> <p>Key features include: *   Speed: Heavy lifting is done in C++ using the Eigen library. *   Flexibility: Mix and match different reservoir types and readout algorithms. *   Scalability: Supports large sparse reservoirs and multi-threading.</p>"},{"location":"user_guide/#sections","title":"Sections","text":"<ul> <li>Installation: Prerequisites and installation steps.</li> <li>Quick Start: Get up and running with a simple example.</li> <li>Core Concepts: Learn about Reservoirs, Readouts, and Model configuration.</li> <li>Advanced Usage: Explore Online Learning, Generative Prediction, and Parallelization.</li> </ul>"},{"location":"user_guide/advanced_usage/","title":"Advanced Usage","text":""},{"location":"user_guide/advanced_usage/#online-learning","title":"Online Learning","text":"<p>For real-time applications where data arrives sequentially, use <code>partial_fit</code> with an RLS or LMS readout.</p> <pre><code>readout = readouts.Rls(lambda_=0.99, delta=1.0, include_bias=True)\nmodel.set_readout(readout)\n\n# In a loop:\nmodel.partial_fit(x_step, y_step)\n</code></pre>"},{"location":"user_guide/advanced_usage/#generative-prediction","title":"Generative Prediction","text":"<p>To generate sequences autonomously (feeding predictions back as inputs):</p> <pre><code># Prime the reservoir with some initial data\nprime_data = x_test[:100]\n# Generate the next 200 steps\ngenerated = model.predict_generative(prime_data, n_steps=200)\n</code></pre>"},{"location":"user_guide/advanced_usage/#next-generation-rc-nvar","title":"Next-Generation RC (NVAR)","text":"<p><code>rclib</code> supports NVAR, which uses time-delayed features instead of a random network.</p> <pre><code>res = reservoirs.Nvar(num_lags=5)\n# ... use as a normal reservoir\n</code></pre>"},{"location":"user_guide/advanced_usage/#parallelization-configuration","title":"Parallelization Configuration","text":"<p>You can optimize performance for your hardware by configuring CMake options during the build.</p> Option Default Best For <code>RCLIB_USE_OPENMP</code> <code>ON</code> Multi-core CPUs <code>RCLIB_ENABLE_EIGEN_PARALLELIZATION</code> <code>ON</code> Balanced performance (Default) <p>To change these, reinstall with: <pre><code>CMAKE_ARGS=\"-DRCLIB_ENABLE_EIGEN_PARALLELIZATION=OFF\" pip install .\n</code></pre> or via direct CMake configuration if building manually.</p>"},{"location":"user_guide/core_concepts/","title":"Core Concepts","text":""},{"location":"user_guide/core_concepts/#configuring-reservoirs","title":"Configuring Reservoirs","text":"<p>The reservoir is the dynamical core of the ESN. <code>rclib</code> provides <code>RandomSparse</code> for standard ESNs.</p> <pre><code>res = reservoirs.RandomSparse(\n    n_neurons=1000,      # Size of the reservoir\n    spectral_radius=0.9, # Scaling of spectral radius\n    sparsity=0.1,        # Density of connections\n    leak_rate=1.0,       # 1.0 = full update, &lt; 1.0 = leaky integrator\n    input_scaling=1.0,   # Scaling of input weights\n    include_bias=False,  # Add bias neuron to reservoir\n    seed=42              # Random seed for reproducibility\n)\n</code></pre>"},{"location":"user_guide/core_concepts/#configuring-readouts","title":"Configuring Readouts","text":"<p>The readout maps the high-dimensional reservoir state to the target output.</p> <ul> <li>Ridge Regression (<code>readouts.Ridge</code>): The standard offline training method. Fast and stable.</li> <li>Recursive Least Squares (<code>readouts.Rls</code>): For online, adaptive learning.</li> <li>Least Mean Squares (<code>readouts.Lms</code>): A simpler gradient-based online method.</li> </ul>"},{"location":"user_guide/core_concepts/#building-the-model","title":"Building the Model","text":"<p>The <code>ESN</code> class acts as a container.</p> <pre><code>model = ESN(connection_type=\"serial\") # \"serial\" or \"parallel\"\nmodel.add_reservoir(res1)\n# For deep ESNs:\n# model.add_reservoir(res2)\nmodel.set_readout(readout)\n</code></pre>"},{"location":"user_guide/installation/","title":"Installation","text":""},{"location":"user_guide/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Operating System: Linux, macOS, or Windows (tested primarily on Linux).</li> <li>C++ Compiler: Must support C++17 (e.g., GCC 9+, Clang 10+, MSVC 2019+).</li> <li>CMake: Version 3.15 or higher.</li> <li>Python: Version 3.10 or higher.</li> <li>OpenMP: Required for parallelization.<ul> <li>Ubuntu/Debian: <code>sudo apt install libomp-dev</code></li> </ul> </li> </ul>"},{"location":"user_guide/installation/#installing-with-uv-recommended","title":"Installing with <code>uv</code> (Recommended)","text":"<p>The recommended way to install and manage <code>rclib</code> for development is using <code>uv</code>.</p> <pre><code># Clone the repository\ngit clone --recursive https://github.com/hrshtst/rclib.git\ncd rclib\n\n# Install dependencies and the project\nuv sync\n</code></pre>"},{"location":"user_guide/installation/#installing-via-pip","title":"Installing via <code>pip</code>","text":"<p>You can also install it using standard <code>pip</code>:</p> <pre><code>pip install .\n</code></pre> <p>Note: The <code>--recursive</code> flag in git clone is crucial because <code>rclib</code> uses submodules for its C++ dependencies (Eigen, Catch2, pybind11).</p>"},{"location":"user_guide/quick_start/","title":"Quick Start","text":"<p>Here is a minimal example to train an ESN on a simple sine wave task.</p> <pre><code>import numpy as np\nfrom rclib import ESN, readouts, reservoirs\n\n# 1. Prepare data\nx = np.linspace(0, 10, 1000).reshape(-1, 1)\ny = np.sin(x)\n\n# Split into train/test\ntrain_len = 800\nx_train, y_train = x[:train_len], y[:train_len]\nx_test, y_test = x[train_len:], y[train_len:]\n\n# 2. Configure Reservoir\nres = reservoirs.RandomSparse(\n    n_neurons=500,\n    spectral_radius=0.9,\n    sparsity=0.1,\n    leak_rate=0.5,\n    seed=42\n)\n\n# 3. Configure Readout (Ridge Regression)\nreadout = readouts.Ridge(alpha=1e-6, include_bias=True)\n\n# 4. Build Model\nmodel = ESN()\nmodel.add_reservoir(res)\nmodel.set_readout(readout)\n\n# 5. Train\nmodel.fit(x_train, y_train, washout_len=50)\n\n# 6. Predict\ny_pred = model.predict(x_test)\n\n# Calculate error\nmse = np.mean((y_pred - y_test) ** 2)\nprint(f\"Test MSE: {mse:.4e}\")\n</code></pre>"}]}